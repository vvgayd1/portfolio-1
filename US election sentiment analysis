import pandas as pd
import re

# load datasets
train_df = pd.read_csv('Uselectiontrain.csv')
val_df = pd.read_csv('Uselectionval.csv')
test_df = pd.read_csv('Uselectiontest.csv')

# display the first few rows of each
print(train_df.head())
print(val_df.head())
print(test_df.head())

# preprocess the data - can see that there is capital letters, urls, numbers and punctuation which needs to be removed

def preprocess_text(text):
    text = text.lower() 
    text = re.sub(r'http\S+', '', text) # remove urls
    text = re.sub(r'\d+', '', text) # remove numbers
    text = re.sub(r'[^\w\s]', '', text) # remove punctuation
    text = ' '.join(text.split()) # remove extra spaces
    return text

# apply preprocessing to the columns of all the datasets
train_df['cleaned_text'] = train_df['tweet_text'].apply(preprocess_text)
val_df['cleaned_text'] = val_df['tweet_text'].apply(preprocess_text)
test_df['cleaned_text'] = test_df['tweet_text'].apply(preprocess_text)

# engineer features - TF-IDF 
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
# fit on training data 
X_train = vectorizer.fit_transform(train_df['cleaned_text'])
X_val = vectorizer.transform(val_df['cleaned_text'])
X_test = vectorizer.transform(test_df['cleaned_text'])

# train the model - Logistic regression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# train the lr model
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, train_df['sentiment'])

# evaluate on validation set
y_pred = clf.predict(X_val)

# print and evaluate the model 
print(classification_report(val_df['sentiment'], y_pred))

              precision    recall  f1-score   support

    negative       1.00      1.00      1.00         3
     neutral       1.00      1.00      1.00        13
    positive       1.00      1.00      1.00        34

    accuracy                           1.00        50
   macro avg       1.00      1.00      1.00        50
weighted avg       1.00      1.00      1.00        50


# the results look to optimal so compare using test set 

from sklearn.metrics import classification_report, accuracy_score

# Preprocess the test data (cleaning and vectorization)
X_test_cleaned = test_df['tweet_text'].apply(preprocess_text)
X_test_vectorized = vectorizer.transform(X_test_cleaned)

# Predict on the test set
y_test_pred = clf.predict(X_test_vectorized)

# Evaluate the performance on the test set
print("Test Set Evaluation:")
print(classification_report(test_df['sentiment'], y_test_pred))

# Accuracy score on the test set
accuracy = accuracy_score(test_df['sentiment'], y_test_pred)
print(f"Test Accuracy: {accuracy:.2f}")

Test Set Evaluation:
              precision    recall  f1-score   support

    negative       1.00      1.00      1.00         3
     neutral       1.00      1.00      1.00        13
    positive       1.00      1.00      1.00        34

    accuracy                           1.00        50
   macro avg       1.00      1.00      1.00        50
weighted avg       1.00      1.00      1.00        50

Test Accuracy: 1.00


# using SVM to cross-validate 

# use TF-IDF to transform data 
# train the model on the training data and evaluate on test set just like the LR model

from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score

# Train an SVM classifier
svm_clf = SVC(kernel='linear')  # Linear kernel for text classification
svm_clf.fit(X_train, train_df['sentiment'])

# Predict on the test set
y_test_pred_svm = svm_clf.predict(X_test)

# Evaluate the performance on the test set
print("SVM Test Set Evaluation:")
print(classification_report(test_df['sentiment'], y_test_pred_svm))

# Accuracy score on the test set
svm_accuracy = accuracy_score(test_df['sentiment'], y_test_pred_svm)
print(f"SVM Test Accuracy: {svm_accuracy:.2f}")

SVM Test Set Evaluation:
              precision    recall  f1-score   support

    negative       1.00      1.00      1.00         3
     neutral       1.00      1.00      1.00        13
    positive       1.00      1.00      1.00        34

    accuracy                           1.00        50
   macro avg       1.00      1.00      1.00        50
weighted avg       1.00      1.00      1.00        50

SVM Test Accuracy: 1.00

# want to visualise the sentiment data 

import matplotlib.pyplot as plt
import seaborn as sns

# get the sentiment predictions from the SVM model
sentiment_predictions = y_test_pred_svm

# plot the distribution 
plt.figure(figsize=(8, 6))
sns.countplot(x=sentiment_predictions, palette='Set2')

# add labels and title so we know what's going on
plt.title("Sentiment Distibution of the 2024 US Election", fontsize=16)
plt.xlabel("Sentiment", fontsize=12)
plt.ylabel("Count", fontsize=12)
plt.xticks(ticks=[0, 1, 2], labels=['Negative', 'Neutral', 'Positive'])

# show the plot
plt.show()



